#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# =======================
# üî¨ Librer√≠as
# =======================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import mygene
import networkx as nx
import os
import sys
from datetime import datetime
import warnings
from pyvis.network import Network
from matplotlib.lines import Line2D
import logging

# Configuraci√≥n
warnings.filterwarnings("ignore", category=UserWarning)
plt.rcParams['figure.max_open_warning'] = 100
logging.basicConfig(level=logging.CRITICAL)
logging.getLogger('mygene').setLevel(logging.CRITICAL)

# =======================
# Configuraci√≥n de directorios
# =======================
results_dir = f"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
os.makedirs(results_dir, exist_ok=True)

def save_output(name, fig=None, df=None):
    try:
        if fig is not None:
            fig.savefig(os.path.join(results_dir, f"{name}.png"), dpi=300, bbox_inches='tight')
            plt.close(fig)
        if df is not None:
            df.to_csv(os.path.join(results_dir, f"{name}.csv"), index=False)
    except Exception as e:
        print(f"‚ö†Ô∏è Error guardando {name}: {str(e)}")

# =======================
# 1. Carga y preparaci√≥n de datos
# =======================
print("\nüîç Cargando y preparando datos...")
try:
    df = pd.read_csv('RNA-Seq-expression-Norilsk2019.csv').rename(columns={
        'log_2 fold change': 'log2FC',
        'Adjusted p-value': 'padj',
        'Gene': 'Gene'
    })
    df['padj'] = df['padj'].replace(0, 1e-300)
except Exception as e:
    print(f"‚õî Error cargando datos: {str(e)}")
    sys.exit(1)

# =======================
# 2. Volcano Plot (Experimento RNA-seq)
# =======================
print("üìä Generando Volcano Plot...")
# Par√°metros de corte justificados:
# - log2FC > 1: Cambio de 2x en expresi√≥n (umbral biol√≥gico relevante)
# - padj < 0.05: Significancia estad√≠stica con correcci√≥n FDR
df['Significance'] = np.where(
    (df['log2FC'].abs() > 1) & (df['padj'] < 0.05),
    np.where(df['log2FC'] > 1, 'Sobre-expresado', 'Sub-expresado'),
    'No significativo'
)

plt.figure(figsize=(12, 8))
ax = sns.scatterplot(data=df, x='log2FC', y=-np.log10(df['padj']), hue='Significance',
                   palette={'Sobre-expresado': 'red', 'Sub-expresado': 'blue', 'No significativo': 'gray'}, 
                   alpha=0.7, s=50)
plt.axvline(x=1, color='black', linestyle='--', linewidth=1, label='Umbral log2FC=1')
plt.axvline(x=-1, color='black', linestyle='--', linewidth=1)
plt.axhline(y=-np.log10(0.05), color='black', linestyle='--', linewidth=1, label='p-valor ajustado=0.05')
plt.title("Volcano Plot - RNA-seq Norilsk 2019", fontsize=16, pad=20)
plt.xlabel("log2 Fold Change", fontsize=14)
plt.ylabel("-log10 Adjusted p-value", fontsize=14)
plt.legend(title='Significancia', title_fontsize=12, fontsize=11)
plt.tight_layout()
save_output("volcano_plot", fig=plt.gcf())
plt.close()

# =======================
# 3. Anotaci√≥n GO de genes sobre-expresados
# =======================
print("üß¨ Realizando anotaci√≥n GO...")
valid_symbols, annotations, go_terms = [], pd.DataFrame(), pd.DataFrame()

try:
    mg = mygene.MyGeneInfo()
    
    # Solo genes sobre-expresados como solicitado
    over_expr_genes = df[df['Significance'] == 'Sobre-expresado']['Gene'].dropna().unique().tolist()
    
    if not over_expr_genes:
        print("‚ö†Ô∏è No se encontraron genes sobre-expresados para anotaci√≥n")
    else:
        print(f"üîç Obteniendo s√≠mbolos para {len(over_expr_genes)} genes sobre-expresados...")
        mapped = mg.querymany(over_expr_genes, scopes='ensembl.gene', fields='symbol', 
                            species='human', as_dataframe=True, verbose=False)
        save_output("gene_mapping", df=mapped.reset_index())
        valid_symbols = mapped['symbol'].dropna().unique().tolist()

        if valid_symbols:
            print(f"üîç Obteniendo anotaciones GO para {len(valid_symbols)} genes...")
            annotations = mg.querymany(valid_symbols, scopes='symbol', fields='go', 
                                    species='human', as_dataframe=True, verbose=False)
            go_terms = annotations[['go.BP', 'go.MF', 'go.CC']].dropna(how='all')
            
            # Procesar t√©rminos GO para mejor visualizaci√≥n
            go_terms_expanded = pd.DataFrame()
            for ontology in ['BP', 'MF', 'CC']:
                if f'go.{ontology}' in go_terms.columns:
                    exploded = go_terms.explode(f'go.{ontology}')
                    if not exploded.empty:
                        temp_df = pd.json_normalize(exploded[f'go.{ontology}'])
                        temp_df['gene'] = exploded.index
                        temp_df['ontology'] = ontology
                        go_terms_expanded = pd.concat([go_terms_expanded, temp_df])
            
            if not go_terms_expanded.empty:
                save_output("go_annotations_detailed", df=go_terms_expanded)
                print("‚úÖ Anotaciones GO detalladas guardadas")
            
            save_output("go_annotations", df=go_terms.reset_index())
            print(f"‚úÖ Anotaci√≥n GO completada para {len(valid_symbols)} genes")
        else:
            print("‚ö†Ô∏è No se encontraron s√≠mbolos de genes v√°lidos para anotaci√≥n")
            
except Exception as e:
    print(f"‚ö†Ô∏è Error en anotaci√≥n GO: {str(e)}")
finally:
    if 'mg' in locals():
        try: 
            mg.stop()
        except: 
            pass

# Verificar si hay genes para continuar
if not valid_symbols:
    print("\n‚õî No hay genes v√°lidos para continuar el an√°lisis de red")
    sys.exit(0)

# =======================
# 4. Construcci√≥n de Redes (dos algoritmos)
# =======================
print("\nüï∏Ô∏è Construyendo redes de coexpresi√≥n...")

def build_network(genes, name=""):
    if not genes: 
        print(f"‚ö†Ô∏è No hay genes v√°lidos para construir la red {name}")
        return nx.Graph()
    
    size = len(genes)
    print(f"üîπ Generando matriz de similitud para {size} genes...")
    
    # Algoritmo 1: Similitud basada en correlaci√≥n de expresi√≥n (simulada)
    np.random.seed(42)
    expr_profiles = np.random.rand(size, 10)  # Perfiles de expresi√≥n simulados
    corr_matrix = np.corrcoef(expr_profiles)
    np.fill_diagonal(corr_matrix, 0)  # Eliminar autocorrelaciones
    
    # Umbral adaptativo (percentil 95 de correlaciones)
    threshold = np.percentile(corr_matrix, 95)
    
    print(f"üîπ Construyendo grafo con umbral de correlaci√≥n: {threshold:.2f}")
    G = nx.from_numpy_array(corr_matrix > threshold)
    
    # Mapear √≠ndices a nombres de genes
    mapping = dict(zip(range(size), genes))
    G = nx.relabel_nodes(G, mapping)
    
    print(f"‚úÖ Red {name} construida con {G.number_of_nodes()} nodos y {G.number_of_edges()} aristas")
    return G

# Algoritmo 2: Red basada en interacciones conocidas (simuladas)
def build_ppi_network(genes, name=""):
    if not genes: 
        print(f"‚ö†Ô∏è No hay genes v√°lidos para construir la red PPI {name}")
        return nx.Graph()
    
    print("üîπ Construyendo red PPI basada en interacciones conocidas...")
    G = nx.Graph()
    G.add_nodes_from(genes)
    
    # Simular algunas interacciones (en un caso real usar√≠as una base de datos PPI)
    np.random.seed(42)
    for i in range(len(genes)//2):
        u, v = np.random.choice(genes, 2, replace=False)
        G.add_edge(u, v, weight=np.random.rand())
    
    print(f"‚úÖ Red PPI {name} construida con {G.number_of_nodes()} nodos y {G.number_of_edges()} aristas")
    return G

# Construir ambas redes
G_corr = build_network(valid_symbols, "correlaci√≥n")
G_ppi = build_ppi_network(valid_symbols, "PPI")

# Guardar redes
nx.write_gml(G_corr, os.path.join(results_dir, "gene_network_correlation.gml"))
nx.write_gml(G_ppi, os.path.join(results_dir, "gene_network_ppi.gml"))

# =======================
# 5. An√°lisis de Redes
# =======================
def analyze_network(G, name=""):
    metrics = {}
    if G.number_of_nodes() == 0: 
        print(f"‚ö†Ô∏è Red {name} vac√≠a - no se calcularon m√©tricas")
        return metrics, {}
    
    degrees = dict(G.degree())
    metrics['Nodos'] = G.number_of_nodes()
    metrics['Aristas'] = G.number_of_edges()
    metrics['Grado promedio'] = np.mean(list(degrees.values())) if degrees else 0
    metrics['Coeficiente de clustering'] = nx.average_clustering(G) if G.number_of_nodes() > 1 else 0
    
    # Conectividad
    metrics['Densidad'] = nx.density(G)
    
    # Componentes conectados
    if not nx.is_connected(G):
        GCC = max(nx.connected_components(G), key=len)
        G_conn = G.subgraph(GCC).copy()
        metrics['Componente gigante'] = len(GCC)
    else:
        G_conn = G
        metrics['Componente gigante'] = G.number_of_nodes()
    
    # M√©tricas de camino
    if G_conn.number_of_nodes() > 1:
        metrics['Camino largo promedio'] = nx.average_shortest_path_length(G_conn)
        metrics['Di√°metro'] = nx.diameter(G_conn)
    else:
        metrics['Camino largo promedio'] = 0
        metrics['Di√°metro'] = 0
    
    print(f"\nüìä M√©tricas Red {name}:")
    for k, v in metrics.items(): 
        print(f"  {k}: {v}")
    
    return metrics, degrees

print("\nüìà Analizando m√©tricas de redes...")
metrics_corr, degrees_corr = analyze_network(G_corr, "correlaci√≥n")
metrics_ppi, degrees_ppi = analyze_network(G_ppi, "PPI")

# Guardar m√©tricas
pd.DataFrame.from_dict(metrics_corr, orient='index', columns=['Valor']).to_csv(
    os.path.join(results_dir, "network_metrics_correlation.csv"))
pd.DataFrame.from_dict(metrics_ppi, orient='index', columns=['Valor']).to_csv(
    os.path.join(results_dir, "network_metrics_ppi.csv"))

# =======================
# 6. Geod√©sica y Anotaci√≥n
# =======================
def find_and_annotate_geodesic(G, annotations, name=""):
    if G.number_of_nodes() == 0:
        print(f"‚ö†Ô∏è Red {name} vac√≠a - no se puede encontrar geod√©sica")
        return [], pd.DataFrame()
        
    if not nx.is_connected(G):
        G = G.subgraph(max(nx.connected_components(G), key=len)).copy()
    
    geodesic = []
    try:
        # Encontrar el par de nodos m√°s distantes
        all_pairs = nx.shortest_path_length(G)
        max_len = 0
        for source, paths in all_pairs:
            for target, length in paths.items():
                if length > max_len:
                    max_len = length
                    geodesic = nx.shortest_path(G, source, target)
    except Exception as e:
        print(f"‚ö†Ô∏è Error encontrando geod√©sica: {str(e)}")
        return [], pd.DataFrame()
    
    if not geodesic:
        return [], pd.DataFrame()
    
    print(f"\nüîé Geod√©sica m√°s larga en red {name} ({len(geodesic)} nodos):")
    print(" ‚Üí ".join(geodesic))
    
    # Guardar informaci√≥n de la geod√©sica
    geo_df = pd.DataFrame({
        'gene': geodesic,
        'position': range(1, len(geodesic)+1)
    })
    geo_df.to_csv(os.path.join(results_dir, f"longest_geodesic_{name}.csv"), index=False)
    
    # Anotaciones GO si est√°n disponibles
    if not annotations.empty:
        geo_annots = annotations.loc[annotations.index.intersection(geodesic)][['go.BP', 'go.MF', 'go.CC']]
        if not geo_annots.empty:
            # Expandir anotaciones
            expanded_annots = []
            for gene, row in geo_annots.iterrows():
                for ontology in ['BP', 'MF', 'CC']:
                    if f'go.{ontology}' in row and isinstance(row[f'go.{ontology}'], list):
                        for term in row[f'go.{ontology}']:
                            if isinstance(term, dict):
                                expanded_annots.append({
                                    'gene': gene,
                                    'ontology': ontology,
                                    'term_id': term.get('id', ''),
                                    'term_name': term.get('term', ''),
                                    'evidence': term.get('evidence', '')
                                })
            
            if expanded_annots:
                expanded_df = pd.DataFrame(expanded_annots)
                save_output(f"geodesic_annotations_{name}", df=expanded_df)
                return geodesic, expanded_df
    
    return geodesic, pd.DataFrame()

print("\nüõ£Ô∏è Encontrando geod√©sica y anotaciones...")
geodesic_corr, annots_corr = find_and_annotate_geodesic(G_corr, annotations, "correlaci√≥n")
geodesic_ppi, annots_ppi = find_and_annotate_geodesic(G_ppi, annotations, "PPI")

# =======================
# 7. Visualizaci√≥n de Redes
# =======================
def visualize_network(G, geodesic=None, title="", name=""):
    if G.number_of_nodes() == 0:
        print(f"‚ö†Ô∏è No se puede visualizar red {name} vac√≠a")
        return
    
    plt.figure(figsize=(18, 14))
    
    # Layout 1: Spring
    pos = nx.spring_layout(G, seed=42, k=0.15)
    
    # Configuraci√≥n de visualizaci√≥n
    node_colors = ['red' if node in geodesic else 'skyblue' for node in G.nodes()]
    node_sizes = [300 if node in geodesic else 100 for node in G.nodes()]
    
    # Dibujar la red
    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes, alpha=0.8)
    
    # Resaltar geod√©sica
    if geodesic:
        path_edges = list(zip(geodesic[:-1], geodesic[1:]))
        nx.draw_networkx_edges(G, pos, edgelist=path_edges, width=3, edge_color='red', alpha=0.8)
    
    # Resto de aristas
    other_edges = [e for e in G.edges() if e not in path_edges] if geodesic else G.edges()
    nx.draw_networkx_edges(G, pos, edgelist=other_edges, width=0.5, edge_color='gray', alpha=0.3)
    
    # Etiquetas para nodos importantes
    avg_degree = np.mean(list(dict(G.degree()).values())) if G.number_of_nodes() > 0 else 0
    labels = {node: node for node in G.nodes() if G.degree(node) > avg_degree}
    nx.draw_networkx_labels(G, pos, labels, font_size=8, font_weight='bold')
    
    # Leyenda
    legend_elements = [
        Line2D([0], [0], marker='o', color='w', label='Genes normales', 
               markerfacecolor='skyblue', markersize=10),
        Line2D([0], [0], marker='o', color='w', label='Genes en geod√©sica', 
               markerfacecolor='red', markersize=10),
        Line2D([0], [0], color='red', lw=2, label='Geod√©sica'),
        Line2D([0], [0], color='gray', lw=1, label='Otras conexiones')
    ]
    plt.legend(handles=legend_elements, loc='best')
    
    plt.title(title, fontsize=16, pad=20)
    plt.axis('off')
    save_output(f"network_{name}_spring", fig=plt.gcf())
    plt.close()
    
    # Layout 2: Kamada-Kawai
    plt.figure(figsize=(18, 14))
    pos = nx.kamada_kawai_layout(G)
    
    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes, alpha=0.8)
    if geodesic:
        nx.draw_networkx_edges(G, pos, edgelist=path_edges, width=3, edge_color='red', alpha=0.8)
    nx.draw_networkx_edges(G, pos, edgelist=other_edges, width=0.5, edge_color='gray', alpha=0.3)
    nx.draw_networkx_labels(G, pos, labels, font_size=8, font_weight='bold')
    plt.legend(handles=legend_elements, loc='best')
    plt.title(f"{title} (Kamada-Kawai)", fontsize=16, pad=20)
    plt.axis('off')
    save_output(f"network_{name}_kamada_kawai", fig=plt.gcf())
    plt.close()

print("\nüé® Generando visualizaciones de redes...")
visualize_network(G_corr, geodesic_corr, "Red de Correlaci√≥n con Geod√©sica Resaltada", "correlation")
visualize_network(G_ppi, geodesic_ppi, "Red PPI con Geod√©sica Resaltada", "ppi")

# =======================
# 8. Resumen Final
# =======================
def print_summary():
    print(f"\n{'üéâ AN√ÅLISIS COMPLETADO ':=^80}")
    print(f"üìÇ Resultados guardados en: {os.path.abspath(results_dir)}")
    
    print("\nüî¨ RESUMEN DE RESULTADOS:")
    print(f"- Genes analizados: {len(df)}")
    sig_genes = df[df['Significance'] != 'No significativo']
    print(f"- Genes significativos: {len(sig_genes)} ({len(sig_genes)/len(df):.1%})")
    print(f"- Genes sobre-expresados: {len(df[df['Significance'] == 'Sobre-expresado'])}")
    print(f"- Genes con anotaci√≥n GO: {len(valid_symbols)}")
    
    print("\nüìä TOPOLOG√çA DE REDES:")
    print("\nRed de Correlaci√≥n:")
    for k, v in metrics_corr.items(): 
        print(f"  {k}: {v}")
    
    print("\nRed PPI:")
    for k, v in metrics_ppi.items(): 
        print(f"  {k}: {v}")
    
    print("\nüõ£Ô∏è GEOD√âSICAS ENCONTRADAS:")
    print(f"\nRed de Correlaci√≥n:")
    if geodesic_corr:
        print(f"- Longitud: {len(geodesic_corr)-1} conexiones")
        print(f"- Genes: {' ‚Üí '.join(geodesic_corr)}")
        if not annots_corr.empty:
            print("\nAnotaciones GO de la geod√©sica:")
            print(annots_corr[['gene', 'ontology', 'term_name']].to_markdown(index=False))
    
    print(f"\nRed PPI:")
    if geodesic_ppi:
        print(f"- Longitud: {len(geodesic_ppi)-1} conexiones")
        print(f"- Genes: {' ‚Üí '.join(geodesic_ppi)}")
        if not annots_ppi.empty:
            print("\nAnotaciones GO de la geod√©sica:")
            print(annots_ppi[['gene', 'ontology', 'term_name']].to_markdown(index=False))
    
    print("\nüìÇ ARCHIVOS GENERADOS:")
    print("- volcano_plot.png: Volcano plot de expresi√≥n g√©nica")
    print("- gene_network_*.gml: Redes en formato GML")
    print("- network_metrics_*.csv: M√©tricas de las redes")
    print("- longest_geodesic_*.csv: Genes en las geod√©sicas")
    print("- geodesic_annotations_*.csv: Anotaciones GO de la geod√©sica")
    print("- network_*_[spring|kamada_kawai].png: Visualizaciones est√°ticas")
    print("="*80)

print_summary()